"""
Label Region Extractor - Python Implementation
Chuyá»ƒn Ä‘á»•i tá»« C# LabelRegionExtractor.cs

Há»‡ thá»‘ng 2 táº§ng (Ä‘Ã£ cáº­p nháº­t):
- Táº¦NG 1: Analysis (phÃ¢n tÃ­ch histogram vÃ  contrast)
- Táº¦NG 2: Strategies (2 chiáº¿n lÆ°á»£c: HIGH/LOW)
- Fallback Chain: HIGHâ†’LOW, LOWâ†’STOP
"""

import cv2
import numpy as np
from dataclasses import dataclass
from typing import Optional, Tuple
import matplotlib.pyplot as plt
from pathlib import Path
import json

# ============================================================================
# CONSTANTS
# ============================================================================

# Expansion factors (dá»±a trÃªn vá»‹ trÃ­ CENTER-RIGHT cá»§a QR trong nhÃ£n)
QR_VERTICAL_CENTER_UP = 1.0      # Má»Ÿ rá»™ng 1.0Ã— lÃªn trÃªn
QR_VERTICAL_CENTER_DOWN = 1.2    # Má»Ÿ rá»™ng 1.2Ã— xuá»‘ng dÆ°á»›i (thÃªm 0.2Ã— padding)
QR_HORIZONTAL_RIGHT = 0.2        # Má»Ÿ rá»™ng 0.2Ã— sang pháº£i (thÃªm padding pháº£i)
QR_LEFT_EXPANSION = 3.5          # Má»Ÿ rá»™ng 3.5Ã— sang trÃ¡i

# Padding Ä‘á»ƒ trÃ¡nh cáº¯t nháº§m (tÃ¹y chá»n)
PADDING_RATIO = 0.1              # 10% padding chung cho táº¥t cáº£ cÃ¡c cáº¡nh (dá»±a trÃªn kÃ­ch thÆ°á»›c QR)

# Debug output directory
DEBUG_OUTPUT_DIR = "data/debug"


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def get_analysis_region(gray: np.ndarray) -> np.ndarray:
    """
    Láº¥y vÃ¹ng Ä‘á»ƒ phÃ¢n tÃ­ch.
    
    TrÆ°á»›c: Láº¥y 1/3 center (vÃ¬ áº£nh lá»›n, nhÃ£n á»Ÿ giá»¯a)
    Hiá»‡n táº¡i: Láº¥y toÃ n bá»™ áº£nh (vÃ¬ input Ä‘Ã£ lÃ  vÃ¹ng nhá» chá»©a nhÃ£n)
    
    Args:
        gray: áº¢nh grayscale
    
    Returns:
        Region Ä‘á»ƒ phÃ¢n tÃ­ch (toÃ n bá»™ áº£nh)
    """
    return gray


def save_debug_image(image: np.ndarray, filename: str, cmap='gray'):
    """
    LÆ°u áº£nh debug.
    
    Args:
        image: áº¢nh cáº§n lÆ°u
        filename: TÃªn file (sáº½ tá»± Ä‘á»™ng thÃªm prefix debug_)
        cmap: Colormap cho matplotlib
    """
    output_dir = Path(DEBUG_OUTPUT_DIR)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_path = output_dir / f"debug_{filename}"
    
    if len(image.shape) == 2:  # Grayscale
        plt.figure(figsize=(10, 6))
        plt.imshow(image, cmap=cmap)
        plt.colorbar()
        plt.title(filename)
        plt.axis('off')
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
    else:  # Color (BGR -> RGB)
        plt.figure(figsize=(10, 6))
        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        plt.title(filename)
        plt.axis('off')
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
    
    print(f"  ğŸ’¾ Saved debug: {output_path}")


def save_debug_json(data: dict, filename: str):
    """
    LÆ°u dá»¯ liá»‡u debug dáº¡ng JSON.
    
    Args:
        data: Dictionary chá»©a dá»¯ liá»‡u
        filename: TÃªn file (sáº½ tá»± Ä‘á»™ng thÃªm prefix debug_)
    """
    output_dir = Path(DEBUG_OUTPUT_DIR)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_path = output_dir / f"debug_{filename}"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    
    print(f"  ğŸ’¾ Saved debug: {output_path}")


# ============================================================================
# DATA STRUCTURES
# ============================================================================

@dataclass
class ContrastAnalysisResult:
    """Káº¿t quáº£ phÃ¢n tÃ­ch Ä‘á»™ tÆ°Æ¡ng pháº£n (Ä‘Ã£ cáº­p nháº­t)."""
    level: str  # 'High' hoáº·c 'Low'
    final_score: float
    
    # 2 metrics
    separation: float
    contrast_ratio: float
    
    # Debug info
    peak1_position: int
    peak2_position: int
    trough_position: int  # NgÆ°á»¡ng Ä‘á» xuáº¥t cho HIGH strategy
    mean_intensity: float
    stddev_intensity: float


# ============================================================================
# Táº¦NG 1: ANALYSIS METHODS
# ============================================================================

def analyze_histogram(gray: np.ndarray) -> Tuple[int, int, int, float]:
    """
    PhÃ¢n tÃ­ch histogram Ä‘á»ƒ tÃ¬m 2 peaks, 1 trough vÃ  tÃ­nh separation.
    
    Logic:
    1. Láº¥y vÃ¹ng phÃ¢n tÃ­ch (toÃ n bá»™ áº£nh)
    2. TÃ­nh histogram 256 bins
    3. Smooth báº±ng moving average 5 bins
    4. TÃ¬m local maxima (> 0.5 avgHeight, cÃ¡ch nhau >30 bins)
    5. Chá»n 2 peaks cao nháº¥t, sort theo position
    6. TÃ¬m trough (Ä‘iá»ƒm tháº¥p nháº¥t giá»¯a 2 peaks)
    7. separation = |peak2 - peak1| / 255.0
    
    Returns:
        (peak1_pos, peak2_pos, trough_pos, separation)
    """
    # 1. Láº¥y vÃ¹ng phÃ¢n tÃ­ch
    analysis_roi = get_analysis_region(gray)
    
    # 2. Histogram
    hist = cv2.calcHist([analysis_roi], [0], None, [256], [0, 256])
    hist = hist.flatten()
    
    # 3. Smooth (moving average 5 bins)
    smoothed = np.copy(hist)
    for i in range(2, 254):
        smoothed[i] = np.mean(hist[i-2:i+3])
    
    # 4. Find local maxima
    avg_height = np.mean(smoothed)
    threshold = avg_height * 0.5
    
    peaks = []
    for i in range(10, 246):
        is_local_max = (smoothed[i] > smoothed[i-1] and 
                       smoothed[i] > smoothed[i+1] and 
                       smoothed[i] > threshold)
        
        if is_local_max:
            # Check not too close to existing peaks
            too_close = any(abs(p[0] - i) < 30 for p in peaks)
            if not too_close:
                peaks.append((i, smoothed[i]))
    
    # 5. Take 2 highest peaks and find trough
    peak1, peak2, trough_pos, separation = 0, 0, 127, 0.0
    
    if len(peaks) >= 2:
        # Láº¥y 2 peaks cao nháº¥t, sort theo vá»‹ trÃ­
        peaks = sorted(peaks, key=lambda x: x[1], reverse=True)[:2]
        peaks = sorted(peaks, key=lambda x: x[0])
        
        peak1 = peaks[0][0]
        peak2 = peaks[1][0]
        separation = abs(peak2 - peak1) / 255.0
        
        # TÃ¬m trough (Ä‘iá»ƒm tháº¥p nháº¥t giá»¯a 2 peaks)
        if peak1 < peak2:
            trough_pos = np.argmin(smoothed[peak1:peak2+1]) + peak1
        else:
            trough_pos = 127  # Fallback
            
    elif len(peaks) == 1:
        # Náº¿u chá»‰ cÃ³ 1 peak, set giÃ¡ trá»‹ máº·c Ä‘á»‹nh
        peak1 = peaks[0][0]
        peak2 = peak1
        trough_pos = 127
        separation = 0.0
    else:
        # KhÃ´ng cÃ³ peak nÃ o
        peak1 = 0
        peak2 = 255
        trough_pos = 127
        separation = 0.0
    
    # Debug: Váº½ histogram vá»›i peaks vÃ  trough
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(hist, color='gray', alpha=0.5, label='Original')
    plt.plot(smoothed, color='blue', label='Smoothed')
    plt.axvline(peak1, color='red', linestyle='--', label=f'Peak1={peak1}')
    plt.axvline(peak2, color='green', linestyle='--', label=f'Peak2={peak2}')
    plt.axvline(trough_pos, color='purple', linestyle=':', 
                label=f'Trough={trough_pos} (Threshold)')
    plt.title(f'Histogram Analysis (Separation={separation:.3f})')
    plt.xlabel('Intensity')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    plt.imshow(analysis_roi, cmap='gray')
    plt.title('Analysis Region')
    plt.axis('off')
    
    plt.tight_layout()
    output_path = Path(DEBUG_OUTPUT_DIR) / "debug_01_histogram.png"
    Path(DEBUG_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  ğŸ’¾ Saved debug: {output_path}")
    
    return (peak1, peak2, trough_pos, separation)


# analyze_edges() ÄÃƒ Bá»Š LOáº I Bá»


def analyze_contrast(gray: np.ndarray) -> Tuple[float, float, float]:
    """
    PhÃ¢n tÃ­ch contrast báº±ng standard deviation.
    
    Logic:
    1. Láº¥y vÃ¹ng phÃ¢n tÃ­ch (toÃ n bá»™ áº£nh)
    2. TÃ­nh mean, stddev
    3. contrast_ratio = stddev / 128.0
    
    Returns:
        (mean, stddev, contrast_ratio)
    """
    # 1. Láº¥y vÃ¹ng phÃ¢n tÃ­ch
    analysis_roi = get_analysis_region(gray)
    
    # 2. Calculate mean and stddev
    mean, stddev = cv2.meanStdDev(analysis_roi)
    mean = mean[0][0]
    stddev = stddev[0][0]
    
    # 3. Contrast ratio
    contrast_ratio = stddev / 128.0
    
    # Debug: LÆ°u JSON vÃ  visualization
    contrast_data = {
        "mean_intensity": float(mean),
        "stddev_intensity": float(stddev),
        "contrast_ratio": float(contrast_ratio),
        "min_intensity": float(np.min(analysis_roi)),
        "max_intensity": float(np.max(analysis_roi)),
        "image_shape": list(analysis_roi.shape)
    }
    
    save_debug_json(contrast_data, "03_contrast.json")
    
    # Váº½ phÃ¢n bá»‘ cÆ°á»ng Ä‘á»™
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.imshow(analysis_roi, cmap='gray')
    plt.title(f'Analysis Region (Mean={mean:.1f}, StdDev={stddev:.1f})')
    plt.colorbar()
    plt.axis('off')
    
    plt.subplot(1, 2, 2)
    plt.hist(analysis_roi.ravel(), bins=256, range=(0, 256), color='blue', alpha=0.7)
    plt.axvline(mean, color='red', linestyle='--', label=f'Mean={mean:.1f}')
    plt.axvline(mean - stddev, color='orange', linestyle=':', label=f'Mean-Ïƒ={mean-stddev:.1f}')
    plt.axvline(mean + stddev, color='orange', linestyle=':', label=f'Mean+Ïƒ={mean+stddev:.1f}')
    plt.title(f'Intensity Distribution (Contrast Ratio={contrast_ratio:.3f})')
    plt.xlabel('Intensity')
    plt.ylabel('Frequency')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    output_path = Path(DEBUG_OUTPUT_DIR) / "debug_03_contrast.png"
    Path(DEBUG_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"  ğŸ’¾ Saved debug: {output_path}")
    
    return (mean, stddev, contrast_ratio)


def analyze_frame(gray: np.ndarray) -> ContrastAnalysisResult:
    """
    PhÃ¢n tÃ­ch frame Ä‘á»ƒ tÃ­nh final score vÃ  xÃ¡c Ä‘á»‹nh contrast level.
    
    Logic Má»šI:
    1. Gá»i 2 hÃ m phÃ¢n tÃ­ch (histogram, contrast)
    2. Final Score = separation * 0.6 + contrast_ratio * 0.4
    3. PhÃ¢n loáº¡i:
       - High: separation > 0 VÃ€ final_score > 0.3
       - Low: CÃ¡c trÆ°á»ng há»£p cÃ²n láº¡i
    
    Returns:
        ContrastAnalysisResult
    """
    # 1. Call 2 analysis methods
    peak1, peak2, trough_pos, separation = analyze_histogram(gray)
    mean, stddev, contrast_ratio = analyze_contrast(gray)
    
    # 2. Calculate Final Score (NEW LOGIC)
    final_score = (separation * 0.6) + (contrast_ratio * 0.4)
    
    # 3. Determine level (NEW LOGIC)
    if separation > 0 and final_score > 0.15:
        level = 'High'
    else:
        level = 'Low'
    
    # 4. Return result
    return ContrastAnalysisResult(
        level=level,
        final_score=final_score,
        separation=separation,
        contrast_ratio=contrast_ratio,
        peak1_position=peak1,
        peak2_position=peak2,
        trough_position=trough_pos,
        mean_intensity=mean,
        stddev_intensity=stddev
    )


# ============================================================================
# Táº¦NG 2: STRATEGY METHODS
# ============================================================================

def detect_with_high_contrast(src: np.ndarray, gray: np.ndarray, 
                             threshold_value: int) -> Tuple:
    """
    Strategy HIGH: Simple Binary Threshold + Morphology.
    
    Logic Má»šI:
    1. Simple Thresholding (dÃ¹ng threshold_value tá»« trough)
    2. Morphology: Open(3x3, 1 iter) â†’ Close(3x3, 2 iters)
    3. FindContours(EXTERNAL)
    4. Chá»n largest contour
    5. MinAreaRect â†’ box
    6. Crop â†’ QR verification
    
    Returns:
        tuple: (rect, box, qr_text, qr_points_180, qr_points) or (None, None, None, None, None)
    """
    print(f"  â†’ Method: Simple Threshold + Morphology (Threshold={threshold_value})")
    
    # Debug Step 0: Save input images
    save_debug_image(src, "high_00_input_src.png")
    save_debug_image(gray, "high_01_input_gray.png", cmap='gray')
    
    # 1. Simple Binary Threshold (Thay tháº¿ Otsu)
    _, binary = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)
    print(f"  â†’ Applied Simple Threshold: {threshold_value}")
    
    # Debug Step 1: Save binary threshold result
    save_debug_image(binary, "high_02_binary_threshold.png", cmap='gray')
    
    # 2. Morphology
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    morph_open = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)
    
    # Debug Step 2a: Save after OPEN operation
    save_debug_image(morph_open, "high_03_morph_open.png", cmap='gray')
    
    morph = cv2.morphologyEx(morph_open, cv2.MORPH_CLOSE, kernel, iterations=2)
    
    # Debug Step 2b: Save after CLOSE operation
    save_debug_image(morph, "high_04_morph_close.png", cmap='gray')
    
    # 3. Find contours
    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, 
                                   cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        print("  âœ— No contours found")
        return (None, None, None, None, None)
    
    print(f"  â†’ Found {len(contours)} contours")
    
    # Debug Step 3: Visualize all contours
    debug_contours = src.copy()
    cv2.drawContours(debug_contours, contours, -1, (0, 255, 0), 2)
    save_debug_image(debug_contours, "high_05_all_contours.png")
    
    # 4. Find largest contour
    biggest = max(contours, key=cv2.contourArea)
    max_area = cv2.contourArea(biggest)
    print(f"  â†’ Largest contour area: {max_area:.0f} pixels")
    
    # Debug Step 4: Visualize largest contour
    debug_largest = src.copy()
    cv2.drawContours(debug_largest, [biggest], -1, (0, 0, 255), 3)
    save_debug_image(debug_largest, "high_06_largest_contour.png")
    
    # 5. MinAreaRect
    rect = cv2.minAreaRect(biggest)
    box = cv2.boxPoints(rect)
    box = np.int32(box)
    
    # Debug Step 5: Visualize MinAreaRect
    debug_rect = src.copy()
    cv2.drawContours(debug_rect, [box], 0, (255, 0, 0), 3)
    # Add corner labels
    for i, pt in enumerate(box):
        cv2.circle(debug_rect, tuple(pt), 8, (255, 255, 0), -1)
        cv2.putText(debug_rect, f"{i}", (pt[0] + 10, pt[1] + 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)
    save_debug_image(debug_rect, "high_07_min_area_rect.png")
    
    # 6. Crop and verify QR
    bound = cv2.boundingRect(biggest)
    x, y, w, h = bound
    
    # Clamp to image bounds
    x = max(0, x)
    y = max(0, y)
    w = min(src.shape[1] - x, w)
    h = min(src.shape[0] - y, h)
    
    label_roi = src[y:y+h, x:x+w]
    
    # Debug Step 6: Save cropped label ROI
    save_debug_image(label_roi, "high_08_label_roi.png")
    
    # QR detection
    qr_detector = cv2.QRCodeDetector()
    qr_text, qr_points_180, _ = qr_detector.detectAndDecode(label_roi)
    
    qr_points = None
    if qr_points_180 is not None and len(qr_points_180) > 0:
        # Reshape if needed (sometimes shape is (1, 4, 2))
        if qr_points_180.ndim == 3:
            qr_points_180 = qr_points_180.reshape(-1, 2)
        
        # Convert to global coordinates
        qr_points = qr_points_180.copy()
        qr_points[:, 0] += x
        qr_points[:, 1] += y
        
        # Debug Step 7: Visualize QR code detection on ROI
        debug_qr_roi = label_roi.copy()
        qr_box_int = qr_points_180.astype(np.int32)
        cv2.polylines(debug_qr_roi, [qr_box_int], True, (0, 255, 0), 2)
        for i, pt in enumerate(qr_points_180):
            pt_int = tuple(pt.astype(int))
            cv2.circle(debug_qr_roi, pt_int, 5, (0, 0, 255), -1)
            cv2.putText(debug_qr_roi, f"QR{i}", (pt_int[0] + 10, pt_int[1] + 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
        save_debug_image(debug_qr_roi, "high_09_qr_detected_roi.png")
    
    if qr_text:
        print(f"  âœ“ QR detected: {qr_text}")
        
        # Debug Step 8: Final result with both label box and QR on original image
        debug_final = src.copy()
        # Draw label box (blue)
        cv2.drawContours(debug_final, [box], 0, (255, 0, 0), 3)
        # Draw QR box (green) if available
        if qr_points is not None:
            qr_box_global = qr_points.astype(np.int32)
            cv2.polylines(debug_final, [qr_box_global], True, (0, 255, 0), 2)
            # Add QR text
            qr_center = qr_points.mean(axis=0).astype(int)
            cv2.putText(debug_final, f"QR: {qr_text}", (qr_center[0] - 50, qr_center[1] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        save_debug_image(debug_final, "high_10_final_result.png")
        return (rect, box, qr_text, qr_points_180, qr_points)
    
    print("  âœ— No QR code found in label region")
    return (None, None, None, None, None)


# detect_with_medium_contrast() ÄÃƒ Bá»Š LOáº I Bá»


def debug_low_strategy_geometry(src: np.ndarray, qr_points: np.ndarray, 
                                box: np.ndarray, p1: np.ndarray, p2: np.ndarray,
                                label_top_right: np.ndarray, label_top_left: np.ndarray,
                                expansion_up: float, expansion_left: float):
    """
    Debug visualization cho LOW strategy geometry.
    Váº½ QR box, label box, vÃ  cÃ¡c vectors má»Ÿ rá»™ng.
    
    Args:
        src: áº¢nh gá»‘c
        qr_points: 4 Ä‘iá»ƒm QR code
        box: 4 gÃ³c label Ä‘Ã£ tÃ­nh
        p1, p2: Äiá»ƒm QR top-right vÃ  bottom-right
        label_top_right, label_top_left: GÃ³c label
        expansion_up, expansion_left: Khoáº£ng má»Ÿ rá»™ng
    """
    debug_vis = src.copy()
    
    # Váº½ QR box (Ä‘á»)
    qr_box_int = qr_points.astype(np.int32)
    cv2.polylines(debug_vis, [qr_box_int], True, (0, 0, 255), 2)
    
    # Váº½ label box (xanh lÃ¡)
    cv2.polylines(debug_vis, [box], True, (0, 255, 0), 3)
    
    # Váº½ 4 gÃ³c QR (Ä‘á»)
    for i, pt in enumerate(qr_points):
        pt_int = tuple(pt.astype(int))
        cv2.circle(debug_vis, pt_int, 5, (0, 0, 255), -1)
        cv2.putText(debug_vis, f"QR{i}", (pt_int[0] + 10, pt_int[1] + 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
    
    # Váº½ 4 gÃ³c label (xanh lÃ¡)
    label_names = ["L0:TL", "L1:TR", "L2:BR", "L3:BL"]  # TL=top-left, TR=top-right, etc.
    for i, pt in enumerate(box):
        cv2.circle(debug_vis, tuple(pt), 8, (0, 255, 0), -1)
        cv2.putText(debug_vis, label_names[i], (pt[0] + 10, pt[1] + 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    
    # Váº½ expansion vectors (mÃ u vÃ ng)
    # p1 -> label_top_right (expand UP)
    cv2.arrowedLine(debug_vis, tuple(p1.astype(int)), 
                   tuple(label_top_right.astype(int)), (0, 255, 255), 2)
    mid_pt = ((p1 + label_top_right) / 2).astype(int)
    cv2.putText(debug_vis, f"up:{expansion_up:.0f}px", tuple(mid_pt), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
    
    # label_top_right -> label_top_left (expand LEFT)
    cv2.arrowedLine(debug_vis, tuple(label_top_right.astype(int)), 
                   tuple(label_top_left.astype(int)), (255, 255, 0), 2)
    mid_pt = ((label_top_right + label_top_left) / 2).astype(int)
    cv2.putText(debug_vis, f"left:{expansion_left:.0f}px", tuple(mid_pt), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
    
    # ThÃªm text thÃ´ng tin
    info_y = 30
    cv2.putText(debug_vis, "LOW Strategy Geometry Debug", (10, info_y), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 255), 2)
    info_y += 30
    cv2.putText(debug_vis, "Red: QR box | Green: Label box", (10, info_y), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
    
    save_debug_image(debug_vis, "05_low_geometry_debug.png")
    print(f"  ğŸ’¾ Debug geometry visualization saved")


def try_detect_qr_multiple_methods(src: np.ndarray, gray: np.ndarray) -> Tuple:
    """
    Thá»­ detect QR code vá»›i 3 phÆ°Æ¡ng phÃ¡p preprocessing khÃ¡c nhau.
    Return ngay khi tÃ¬m tháº¥y (early exit).
    
    Methods (theo thá»© tá»± Æ°u tiÃªn):
    1. Gray (CLAHE) - ÄÃ£ qua CLAHE preprocessing, tÄƒng contrast cá»¥c bá»™
    2. Histogram Equalization - TÄƒng contrast toÃ n cá»¥c, "siÃªu tÆ°Æ¡ng pháº£n"
    3. Original BGR - áº¢nh gá»‘c, khÃ´ng xá»­ lÃ½ (fallback cuá»‘i cÃ¹ng)
    
    Args:
        src: áº¢nh BGR gá»‘c
        gray: áº¢nh grayscale Ä‘Ã£ qua CLAHE
    
    Returns:
        (qr_text, qr_points, method_name) or (None, None, None)
    """
    qr_detector = cv2.QRCodeDetector()
    
    # Danh sÃ¡ch cÃ¡c methods Ä‘á»ƒ thá»­
    methods = []
    
    # Method 1: Gray (CLAHE) - ÄÃ£ Ä‘Æ°á»£c apply CLAHE á»Ÿ hÃ m cha
    # ÄÃ¢y lÃ  best candidate vÃ¬ CLAHE tÄƒng contrast cá»¥c bá»™ mÃ  khÃ´ng lÃ m mÃ©o
    methods.append(("gray_clahe", gray))
    
    # Method 2: Histogram Equalization - "SiÃªu tÆ°Æ¡ng pháº£n"
    # TÄƒng contrast toÃ n cá»¥c máº¡nh, hiá»‡u quáº£ nhÆ°ng cÃ³ thá»ƒ mÃ©o QR
    enhanced = cv2.equalizeHist(gray)
    methods.append(("hist_equal", enhanced))
    
    # Method 3: Original BGR - áº¢nh gá»‘c
    # Fallback cuá»‘i cÃ¹ng, Ä‘Ã´i khi má»i preprocessing Ä‘á»u fail mÃ  BGR láº¡i work
    methods.append(("original_bgr", src))
    
    # Thá»­ tá»«ng method, return ngay khi tÃ¬m tháº¥y
    print("  â†’ Trying QR detection with multiple preprocessing methods...")
    for method_name, img in methods:
        qr_text, qr_points, _ = qr_detector.detectAndDecode(img)
        
        # Debug: In chi tiáº¿t káº¿t quáº£ detect
        print(f"     â€¢ Method '{method_name}': text={repr(qr_text)}, points_shape={qr_points.shape if qr_points is not None else 'None'}")
        
        # Check cÃ³ detect Ä‘Æ°á»£c khÃ´ng
        has_text = qr_text and len(qr_text) > 0
        has_points = qr_points is not None and qr_points.size > 0
        
        if has_text and has_points:
            # Reshape náº¿u cáº§n
            if qr_points.ndim == 3:
                qr_points = qr_points.reshape(-1, 2)
            
            if len(qr_points) >= 4:
                print(f"  âœ“ QR detected with method: {method_name}")
                # LÆ°u method thÃ nh cÃ´ng
                save_debug_image(img, f"04_low_qr_success_{method_name}.png", 
                               cmap='gray' if len(img.shape) == 2 else None)
                return qr_text, qr_points, method_name
            else:
                print(f"     âœ— Points count too low: {len(qr_points)}")
    
    # Táº¥t cáº£ methods Ä‘á»u fail
    print("  âœ— QR detection failed with all methods")
    
    # LÆ°u táº¥t cáº£ failed attempts Ä‘á»ƒ debug
    for method_name, img in methods:
        save_debug_image(img, f"04_low_qr_failed_{method_name}.png", 
                       cmap='gray' if len(img.shape) == 2 else None)
    
    return None, None, None


def detect_with_low_contrast(src: np.ndarray, gray: np.ndarray) -> Tuple:
    """
    Strategy LOW: QR-First + Geometry Inference (cho Ã¡o tráº¯ng/kem).
    
    Logic tá»« C# (Ä‘Ã£ cáº­p nháº­t - CENTER-RIGHT positioning):
    1. Multi-method QR detection (gray_clahe â†’ hist_equal â†’ original_bgr)
    2. TÃ­nh geometry QR (vectors, width, height, angle)
    3. Suy luáº­n label vá»›i expansion ratios:
       - Chiá»u cao: 2.0Ã— QR (QR á»Ÿ giá»¯a â†’ má»Ÿ rá»™ng 0.5Ã— lÃªn/xuá»‘ng)
       - Chiá»u rá»™ng: 4.0Ã— QR (QR á»Ÿ pháº£i â†’ má»Ÿ rá»™ng 3.0Ã— sang trÃ¡i)
    4. Construct 4 corners (QR á»Ÿ GIá»®A-PHáº¢I, expand TRÃI + TRÃŠN + DÆ¯á»šI)
    5. Táº¡o RotatedRect tá»« 4 corners
    
    Returns:
        tuple: (rect, box, qr_text, None, qr_points)
        Note: qr_points_180 = None vÃ¬ detect trÃªn toÃ n áº£nh
    """
    print("  â†’ Method: QR-First + Geometry Inference")
    
    # Debug: LÆ°u áº£nh input
    save_debug_image(gray, "04_low_input_gray.png", cmap='gray')
    save_debug_image(src, "04_low_input_src.png")
    
    # 1. Detect QR vá»›i multiple methods
    qr_text, qr_points, method_used = try_detect_qr_multiple_methods(src, gray)
    
    if not qr_text or qr_points is None or len(qr_points) < 4:
        print("  âœ— No QR code detected")
        return (None, None, None, None, None)
    
    # Reshape if needed
    if qr_points.ndim == 3:
        qr_points = qr_points.reshape(-1, 2)
    
    print(f"  âœ“ QR detected: {qr_text}")
    
    # 3. Calculate QR geometry
    p0 = qr_points[0]  # top-left
    p1 = qr_points[1]  # top-right
    p3 = qr_points[3]  # bottom-left
    
    top_vec = p1 - p0
    left_vec = p3 - p0
    
    qr_width = np.linalg.norm(top_vec)
    qr_height = np.linalg.norm(left_vec)
    
    # Unit vectors
    dir_right = top_vec / qr_width
    dir_down = left_vec / qr_height
    
    angle_rad = np.arctan2(top_vec[1], top_vec[0])
    angle_deg = angle_rad * 180.0 / np.pi
    print(f"  â†’ QR geometry: {qr_width:.1f}x{qr_height:.1f} px, angle={angle_deg:.1f}Â°")
    
    # 4. Infer label dimensions and expansion distances
    # QR á»Ÿ GIá»®A-PHáº¢I cá»§a nhÃ£n â†’ má»Ÿ rá»™ng TRÃI, LÃŠN TRÃŠN, XUá»NG DÆ¯á»šI, PHáº¢I
    
    # TÃ­nh Ä‘iá»ƒm QR bottom-right (p2)
    p2 = p3 + (dir_right * qr_width)  # QR bottom-right
    
    # TÃ­nh padding chung (Ã¡p dá»¥ng cho táº¥t cáº£ cÃ¡c cáº¡nh)
    padding_h = qr_height * PADDING_RATIO  # Padding dá»c (10% QR height)
    padding_w = qr_width * PADDING_RATIO   # Padding ngang (10% QR width)
    
    # TÃ­nh khoáº£ng má»Ÿ rá»™ng (bao gá»“m padding chung)
    expansion_up = qr_height * QR_VERTICAL_CENTER_UP + padding_h        # 1.0Ã— + padding
    expansion_down = qr_height * QR_VERTICAL_CENTER_DOWN + padding_h    # 1.2Ã— + padding
    expansion_left = qr_width * QR_LEFT_EXPANSION + padding_w           # 3.5Ã— + padding
    expansion_right = qr_width * QR_HORIZONTAL_RIGHT + padding_w        # 0.2Ã— + padding
    
    # TÃ­nh label dimensions
    label_width = expansion_left + qr_width + expansion_right
    label_height = expansion_up + qr_height + expansion_down
    
    print(f"  â†’ Predicted label: {label_width:.1f}x{label_height:.1f} px")
    print(f"  â†’ Base expansion: â†‘{QR_VERTICAL_CENTER_UP}Ã—QR, â†“{QR_VERTICAL_CENTER_DOWN}Ã—QR, â†{QR_LEFT_EXPANSION}Ã—QR, â†’{QR_HORIZONTAL_RIGHT}Ã—QR")
    print(f"  â†’ Padding: {PADDING_RATIO}Ã—QR = Â±{padding_h:.1f}px (vertical), Â±{padding_w:.1f}px (horizontal)")
    print(f"  â†’ Final expansion: â†‘{expansion_up:.1f}px, â†“{expansion_down:.1f}px, â†{expansion_left:.1f}px, â†’{expansion_right:.1f}px")
    
    # 5. Calculate 4 corners
    # â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â† Label top (1.0Ã—QR + 0.1Ã—padding)
    # â”‚                        â”Œâ”€â”€â”€â”€â”       â”‚
    # â”‚                        â”‚ QR â”‚ â†â”€â”€â”€â”€â”€â”¤  QR gáº§n pháº£i (0.2Ã—QR + 0.1Ã—padding)
    # â”‚                        â””â”€â”€â”€â”€â”˜       â”‚
    # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â† Label bottom (1.2Ã—QR + 0.1Ã—padding)
    # â†‘                                     â†‘
    # TrÃ¡i: 3.5Ã—QR + 0.1Ã—padding             Pháº£i: 0.2Ã—QR + 0.1Ã—padding
    
    # TÃ­nh 4 gÃ³c nhÃ£n
    # 1. Label TOP-RIGHT: tá»« QR top-right (p1) Ä‘i lÃªn rá»“i sang pháº£i
    label_top_right = p1 - (dir_down * expansion_up) + (dir_right * expansion_right)
    
    # 2. Label BOTTOM-RIGHT: tá»« QR bottom-right (p2) Ä‘i xuá»‘ng rá»“i sang pháº£i
    label_bottom_right = p2 + (dir_down * expansion_down) + (dir_right * expansion_right)
    
    # 3. Label TOP-LEFT: tá»« top-right Ä‘i sang trÃ¡i
    label_top_left = label_top_right - (dir_right * label_width)
    
    # 4. Label BOTTOM-LEFT: tá»« bottom-right Ä‘i sang trÃ¡i
    label_bottom_left = label_bottom_right - (dir_right * label_width)
    
    # 6. Create RotatedRect
    label_center = (label_top_left + label_top_right + 
                   label_bottom_right + label_bottom_left) / 4.0
    
    angle = angle_deg
    
    # RotatedRect as tuple (OpenCV format)
    rect = (tuple(label_center), (label_width, label_height), angle)
    
    box = np.array([label_top_left, label_top_right, 
                    label_bottom_right, label_bottom_left], dtype=np.int32)
    
    print(f"  âœ“ Label constructed: center=({label_center[0]:.1f},{label_center[1]:.1f}), angle={angle:.1f}Â°")
    
    # Debug: Váº½ geometry visualization
    debug_low_strategy_geometry(src, qr_points, box, p1, p2, 
                               label_top_right, label_top_left,
                               expansion_up, expansion_left)
    
    # qr_points_180 = None (detect trÃªn toÃ n áº£nh, khÃ´ng cÃ³ ROI cá»¥c bá»™)
    return (rect, box, qr_text, None, qr_points)


# ============================================================================
# HÃ€M CHÃNH: DETECT LABEL REGION
# ============================================================================

def detect_label_region(src: np.ndarray, 
                       **kwargs) -> Tuple[Optional[Tuple], 
                                          Optional[np.ndarray], 
                                          Optional[str],
                                          Optional[np.ndarray],
                                          Optional[np.ndarray],
                                          Optional[str]]:
    """
    PhÃ¡t hiá»‡n vÃ¹ng nhÃ£n trong áº£nh.
    
    Logic CHÃNH XÃC:
    1. Preprocessing: BGR â†’ Gray â†’ GaussianBlur(5x5)
    2. Táº¦NG 1: PhÃ¢n tÃ­ch (AnalyzeFrame) â†’ High/Low, trough_pos
    3. Táº¦NG 2: Routing:
       - HIGH: Thá»­ detect_with_high_contrast()
               â†’ Náº¿u tháº¥t báº¡i, fallback sang detect_with_low_contrast()
       - LOW:  Thá»­ detect_with_low_contrast()
               â†’ Náº¿u tháº¥t báº¡i, Dá»ªNG Láº I (khÃ´ng fallback).
    
    Args:
        src: BGR image (np.ndarray)
    
    Returns:
        tuple: (rect, box, qr_text, qr_points_180, qr_points, strategy_used)
               hoáº·c (None, None, None, None, None, "FAILED") náº¿u tháº¥t báº¡i
    """
    if src is None or src.size == 0:
        return (None, None, None, None, None, None)
    
    try:
        # 1. PREPROCESSING
        gray_blurred = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
        gray_blurred = cv2.GaussianBlur(gray_blurred, (5, 5), 0)
        
        # 2. Táº¦NG 1: PhÃ¢n tÃ­ch (dÃ¹ng áº£nh Ä‘Ã£ blur)
        analysis = analyze_frame(gray_blurred)
        
        # 3. Log analysis
        print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘           FRAME ANALYSIS - AUTO CONTRAST DETECTION            â•‘")
        print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print(f"â•‘  ğŸ“Š Final Score:     {analysis.final_score:6.3f}                              â•‘")
        print(f"â•‘  ğŸ¯ Strategy Level:  {analysis.level:<10} (Primary)                 â•‘")
        print("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        print("â•‘  METRICS BREAKDOWN:                                            â•‘")
        print(f"â•‘    â€¢ Separation:     {analysis.separation:6.3f}  (P1:{analysis.peak1_position:3}, P2:{analysis.peak2_position:3})     â•‘")
        print(f"â•‘    â€¢ Contrast Ratio: {analysis.contrast_ratio:6.3f}  (Ïƒ={analysis.stddev_intensity:6.1f})           â•‘")
        print(f"â•‘    â€¢ HIGH Threshold: {analysis.trough_position:<6} (Trough)                      â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
        
        # 4. Táº¦NG 2: Routing vÃ  Fallback (Logic chÃ­nh xÃ¡c)
        result = None
        strategy_used = ""
        
        if analysis.level == 'High':
            print("ğŸŸ¢ Executing Strategy: HIGH CONTRAST (Primary)")
            # Thá»­ HIGH trÆ°á»›c
            result = detect_with_high_contrast(src, gray_blurred, analysis.trough_position)
            print(f"   Result: {'âœ… SUCCESS' if result[0] is not None else 'âŒ FAILED'}")
            
            if result[0] is not None:
                strategy_used = "HIGH"
            else:
                # Fallback sang LOW
                print("âš ï¸  HIGH failed, falling back to LOW strategy...")
                
                # Chuáº©n bá»‹ áº£nh cho LOW (cáº§n CLAHE)
                clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
                gray_clahe = clahe.apply(gray_blurred)
                print("  â†’ Applied CLAHE preprocessing for fallback")
                
                result = detect_with_low_contrast(src, gray_clahe)
                print(f"   Fallback Result: {'âœ… SUCCESS' if result[0] is not None else 'âŒ FAILED'}")
                if result[0] is not None:
                    strategy_used = "HIGHâ†’LOW"
        
        else: # (analysis.level == 'Low')
            print("ğŸ”´ Executing Strategy: LOW CONTRAST (Primary)")
            
            # Chuáº©n bá»‹ áº£nh cho LOW (cáº§n CLAHE)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            gray_clahe = clahe.apply(gray_blurred)
            print("  â†’ Applied CLAHE preprocessing (adaptive contrast enhancement)")
            
            # Thá»­ LOW
            result = detect_with_low_contrast(src, gray_clahe)
            print(f"   Result: {'âœ… SUCCESS' if result[0] is not None else 'âŒ FAILED'}")
            
            if result[0] is not None:
                strategy_used = "LOW"
            else:
                # KHÃ”NG FALLBACK
                print("âš ï¸  LOW failed. No fallback (Histogram not separable).")
                # strategy_used sáº½ rá»—ng, vÃ  sáº½ Ä‘Æ°á»£c gÃ¡n lÃ  "FAILED" á»Ÿ dÆ°á»›i
        
        # 5. Log final result
        if result[0] is not None:
            qr_text = result[2] if result[2] else "N/A"
            print(f"âœ… FINAL RESULT: Label detected | QR: {qr_text} | Strategy: {strategy_used}")
        else:
            print("âŒ FINAL RESULT: Label NOT detected")
            # GÃ¡n strategy_used = "FAILED" náº¿u khÃ´ng cÃ³ káº¿t quáº£ nÃ o
            strategy_used = strategy_used if strategy_used else "FAILED"
            
        print("")
        
        # 6. Return with strategy_used
        # Äáº£m báº£o tráº£ vá» 6 giÃ¡ trá»‹
        if result[0] is not None:
            return (*result, strategy_used)
        else:
            return (None, None, None, None, None, "FAILED")
    
    except Exception as e:
        print(f"[DetectLabelRegion ERROR] {e}")
        import traceback
        traceback.print_exc()
        return (None, None, None, None, None, None)
